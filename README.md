 Emotion Classification with SVM
This project performs emotion classification on text using a Support Vector Machine (SVM) model. It includes tweet scraping, preprocessing, clustering (unsupervised learning), model training, performance evaluation, persistence, and an optional alert system.

 Project Structure

â”œâ”€â”€ emotions.csv                # Main dataset (pre-labeled)
â”œâ”€â”€ best_svm_model.pkl          # Saved best-performing SVM model
â”œâ”€â”€ tfidf_vectorizer.pkl        # Saved TF-IDF vectorizer
â”œâ”€â”€ label_encoder.pkl           # Saved label encoder
â”œâ”€â”€ emotion_classifier.py       # Main code file (or .ipynb if notebook)
â””â”€â”€ README.md                   # This file
âš™ï¸ Features
âœ… 1. Tweet Scraping (Real-Time)
Uses snscrape to fetch tweets matching emotional keywords (happy, sad, angry, etc.).

Saves them in a DataFrame for classification.

âœ… 2. Text Preprocessing
Lowercasing, URL/user/hashtag removal

Punctuation and number cleaning

Stopword removal

Stemming using PorterStemmer

âœ… 3. Clustering (KMeans)
Applies KMeans clustering to scraped tweets (unsupervised learning)

Helps detect patterns or emotional clusters without labels

âœ… 4. SVM Classification
Trains multiple SVM models using different kernels: linear, poly, rbf, and sigmoid

Evaluates using accuracy, precision, recall, and F1-score

Visualizes confusion matrices

âœ… 5. Model Persistence
Saves:

Best SVM model (best_svm_model.pkl)

TF-IDF vectorizer (tfidf_vectorizer.pkl)

Label encoder (label_encoder.pkl)

âœ… 6. Optional Alerting System
Flags and prints alerts for negative emotions (e.g., sad, angry) from scraped tweets

ğŸ“ˆ Best Model Summary
Kernel	Accuracy	F1-Score
Linear	0.874	0.873
Sigmoid	0.873	0.872
RBF	0.856	0.852
Poly	0.644	0.602

â¡ï¸ Best Performing Kernel: linear
